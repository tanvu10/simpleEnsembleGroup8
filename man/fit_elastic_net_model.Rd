% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/elastic_net_model.R
\name{fit_elastic_net_model}
\alias{fit_elastic_net_model}
\title{Elastic Net Regression Model Fitting with Optional Bagging}
\usage{
fit_elastic_net_model(
  y,
  X,
  alpha = 0.5,
  lambda = NULL,
  model_type = "gaussian",
  add_intercept = TRUE,
  bagging = FALSE,
  R = 100
)
}
\arguments{
\item{y}{Response vector with continuous or binary outcomes.}

\item{X}{Predictor matrix, accepting numeric or factor types.}

\item{alpha}{The elastic net mixing parameter, ranging from 0 (ridge) to 1 (lasso).}

\item{lambda}{Regularization penalty parameter; auto-determined via cross-validation if NULL.}

\item{model_type}{Specifies the model type, 'gaussian' for regression or 'binomial' for classification.}

\item{add_intercept}{Logical indicating whether to include an intercept in the model.}

\item{R}{The number of bootstrap samples for bagging, applicable if bagging is TRUE.}

\item{use_bagging}{Logical for enabling bagging, using multiple bootstrap samples.}
}
\value{
A glmnet model object fitted using elastic net regularization, or an aggregated result from multiple
bootstrap samples if bagging is enabled.
}
\description{
This function fits an elastic net regression model, which utilizes both lasso and ridge regularization
techniques to improve model performance and interpretability. The function is effective for datasets with
multicollinearity or more predictors than observations, adjusting the model complexity by blending L1 and L2
penalties controlled by the alpha parameter. Optionally, bagging can be used to enhance stability and accuracy
in high-variance scenarios through bootstrap aggregating.
}
\examples{
data(mtcars)
X <- mtcars[, c("hp", "wt")]
y <- mtcars$mpg
result_elastic_net <- fit_elastic_net_model(y, X, alpha = 0.5, add_intercept = TRUE, use_bagging = TRUE)
print(result_elastic_net)
}
