% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/lasso_model.R
\name{fit_lasso_model}
\alias{fit_lasso_model}
\title{Lasso Regression Model Fitting with Optional Bagging}
\usage{
fit_lasso_model(
  y,
  X,
  lambda = NULL,
  model_type = "gaussian",
  add_intercept = TRUE,
  bagging = FALSE,
  R = 100
)
}
\arguments{
\item{y}{Response vector with continuous or binary outcomes.}

\item{X}{Matrix of predictors, either numeric or factor types.}

\item{lambda}{Regularization penalty parameter for lasso regression; if NULL, it is determined using cross-validation.}

\item{model_type}{Specifies the model type, 'gaussian' for regression or 'binomial' for classification.}

\item{add_intercept}{Logical indicating whether to include an intercept in the model.}

\item{bagging}{Logical indicating whether to perform bagging.}

\item{R}{The number of bootstrap samples to use if bagging is enabled.}
}
\value{
A glmnet model object fitted with lasso regression, or if bagging is enabled, an aggregated result from
multiple bootstrap samples.
}
\description{
Performs lasso regression using glmnet, optimizing variable selection and shrinkage of coefficients
through L1 regularization. This approach is particularly useful in models with high dimensionality or
multicollinearity among predictors. The function allows specifying whether to include an intercept and
can automatically determine the optimal regularization penalty (lambda) via cross-validation. Optionally,
bagging can be applied to improve model accuracy and robustness against overfitting.
}
\examples{
data(mtcars)
X <- mtcars[, c("hp", "wt")]
y <- mtcars$mpg
result_lasso <- fit_lasso_model(y, X, add_intercept = TRUE, bagging = FALSE)
print(result_lasso)
}
